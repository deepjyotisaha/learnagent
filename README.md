# ğŸ¤– AI4All - Hands-on: Fundamentals of LLM & Agents

Welcome to the **AI4All - Hands-on - Fundamentals of LLM & Agents** project! This repository demonstrates how to build, ground, and extend LLM-powered agents with tool use, memory, and multi-step reasoning, including integration with the Model Context Protocol (MCP).

---


## ğŸ“‚ Project Structure & Conceptual Build-up

The project is organized to help you learn and experiment with LLM agents step by step, from the simplest to the most advanced. Hereâ€™s the recommended order:

| File/Folder                        | Concept/Stage                                                                                 |
|------------------------------------|----------------------------------------------------------------------------------------------|
| `helloworld.py`                    | ğŸŸ¢ **Hello World**: Minimal LLM call, basic prompt/response.                                 |
| `ollama_run_pretrained.py`         | ğŸŸ¢ **Pretrained LLM**: Use a base LLM for simple Q&A.                                        |
| `ollama_run_finetuned.py`          | ğŸŸ¡ **Fine-tuned LLM**: Use a fine-tuned LLM for improved task performance.                   |
| `ollama_run_no_grounding.py`       | ğŸŸ¡ **No Grounding**: LLM agent without external context.                                     |
| `ollama_run_grounding.py`          | ğŸŸ  **Grounding**: Add external context (e.g., policies) to LLM agent.                        |
| `ollama_run_sales_tools.py`        | ğŸŸ  **Tool Use**: LLM agent can call Python sales tools for data analysis.                    |
| `ollama_run_user_memory.py`        | ğŸŸ  **User Memory**: Add persistent user profile/memory to agent.                             |
| `ollama_run_agentx.py`             | ğŸŸ£ **AgentX**: Full agent with LLM, tools, memory, context, and multi-step reasoning.        |
| `ollama_run_agentx_mcp.py`         | ğŸŸ£ **AgentX + MCP**: AgentX with dynamic MCP tool discovery and execution.                   |
| `ollama_run_mcp_try.py`            | ğŸ§ª **MCP Client Example**: Example/test client for MCP tool invocation and debugging.         |
| `mcp_calculator_server.py`         | ğŸ§® **MCP Calculator Server**: Exposes calculator tools (add, subtract, multiply, divide).    |
| `sales_tools.py`                   | ğŸ› ï¸ **Sales Tools**: Python functions for sales data analysis.                               |
| `test_sales_tools.py`              | ğŸ§ª **Sales Tools Tests**: Unit tests for sales tools.                                        |
| `sales_tools_description.json`     | ğŸ“ **Sales Tools Metadata**: Descriptions and parameters for each sales tool.                |
| `sales_data.csv`                   | ğŸ“Š **Sales Data**: Example sales data for use with sales tools.                              |
| `ikea_return_policy.txt`           | ğŸ“„ **Grounding Context**: Example context for grounding agent responses.                     |
| `user_profile.txt`                 | ğŸ‘¤ **User Profile**: Example user memory/profile for the agent.                              |
| `requirements.txt`                 | ğŸ“¦ **Dependencies**: All required Python dependencies for this project.                      |
| `AI4All - Hands-on - Fundamentals of LLM & Agents.code-workspace` | VS Code workspace settings.                             |
| `__pycache__/`                     | Python bytecode cache (auto-generated).                                                      |


---

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone <your-repo-url>
cd "AI4All - Hands-on - Fundamentals of LLM & Agents"
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Start the MCP Calculator Server (if using MCP tools)
```bash
python mcp_calculator_server.py
```
Note: The MCP server is started by the agent, you don't need to start it when using with the agent.

### 4. Run the Agent
 **Standard agent with local tools:**
  ```bash
  python ollama_run_agentx.py
  ```
 **Agent with local and MCP tools:**
  ```bash
  python ollama_run_agentx_mcp.py
  ```

### 5. Interact!
- Follow the prompts in the terminal.
- Try queries like:
  - "What is the sum of 5 and 7?"
  - "Show me the sales trend for the North region."
  - "Add 10 and 20 using the calculator tool."

---

## ğŸ› ï¸ Key Features
- **LLM-powered agent** with context, memory, and tool use
- **Dynamic tool discovery** via MCP protocol
- **Sales analytics tools** for CSV data
- **Calculator tools** (add, subtract, multiply, divide) via MCP
- **Rich terminal UI** with [Rich](https://github.com/Textualize/rich)

---


## ğŸ“„ File Details

- **helloworld.py**: Test if Python is installed.
- **ollama_run_pretrained.py**: Use a base LLM for simple Q&A.
- **ollama_run_finetuned.py**: Use a fine-tuned LLM for improved task performance.
- **ollama_run_no_grounding.py**: LLM agent without external context.
- **ollama_run_grounding.py**: Add external context (e.g., policies) to LLM agent.
- **ollama_run_sales_tools.py**: LLM agent can call Python sales tools for data analysis.
- **ollama_run_user_memory.py**: Add persistent user profile/memory to agent.
- **ollama_run_agentx.py**: Full agent with LLM, tools, memory, context, and multi-step reasoning.
- **ollama_run_agentx_mcp.py**: AgentX with dynamic MCP tool discovery and execution.
- **ollama_run_mcp_try.py**: Example/test client for MCP tool invocation and debugging.
- **mcp_calculator_server.py**: MCP server exposing calculator tools (add, subtract, multiply, divide) via stdio.
- **sales_tools.py**: Implements sales data analysis tools (summarize, filter, trend, total by region, etc.).
- **test_sales_tools.py**: Unit tests for sales tools.
- **sales_tools_description.json**: Descriptions and parameters for each sales tool.
- **sales_data.csv**: Example sales data for use with sales tools.
- **ikea_return_policy.txt**: Example grounding context for the agent.
- **user_profile.txt**: Example user memory/profile for the agent.
- **requirements.txt**: All required Python dependencies for this project.

---

## ğŸ§‘â€ğŸ’» Authors & Credits
- Project by Deepjyoti Saha
- Built with [Rich](https://github.com/Textualize/rich), [MCP](https://github.com/microsoft/mcp), and Python 3.8+

---

## ğŸ“œ License
This project is licensed under the MIT License.

---

Enjoy exploring LLM agents and tool use! ğŸ¤–âœ¨
